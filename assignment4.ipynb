{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exploring the data of Airbnb website. \n",
    "\n",
    "#### Student name: Thai Minh Nguyen\n",
    "#### Student ID: 24002398\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "[Airbnb](https://www.airbnb.co.nz/) was born in 2007 when two hosts welcomed three guests to their San Francisco home, and has since grown to over 5 million hosts who have welcomed over 1.5 billion guest arrivals in almost every country across the globe. Every day, hosts offer unique stays and experiences that make it possible for guests to connect with communities in a more authentic way. My project is to explore the data of Airbnb website in New Zealand. I will crawl the data from the website, then clean and transform it to a structured format. After that, I will analyze the data to find the relationship between the room features, ratings of listing and host, the price and the weather data.\n",
    "\n",
    "#### Datasets used:\n",
    "\n",
    "1. Crawled data from Airbnb website\n",
    "2. Got the weather data from the API\n",
    "\n",
    "#### Dataset sources: \n",
    "\n",
    "1. https://www.airbnb.co.nz/\n",
    "2. https://www.visualcrossing.com/\n",
    "\n",
    "### Research Questions\n",
    "\n",
    "1. Does the room features affect the price?\n",
    "2. Does the ratings of listing and host affect the price?\n",
    "3. Does the weather affect the price?\n",
    "\n",
    "\n",
    "### Executive Summary\n",
    "\n",
    "When we book a Airbnb for a holiday, there are many choices for us. We will compare the price of the listing based on the room features, ratings of the listing and host, and the hosting type and guest favorite. The key findings are: the number of bedrooms and baths increases the price of the house, but it can clearly be understood that the price for the bigger room is for more people. The second finding is not logical, when most of the ratings have negative coefficients in the OLS model, while the higher rating should have a higher price. Finally, we see that on the period that has a clear day or is partly cloudy, the price is higher than the period that has a rainy day or cloudy.\n"
   ],
   "id": "1258f5a25895eeee"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:51:16.671574Z",
     "start_time": "2024-05-28T02:51:16.301831Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import threading\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "\n",
    "cService = webdriver.ChromeService(executable_path='/Users/benminh1201/Downloads/chromedriver-mac-arm64/chromedriver')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8c1c2ebe1d21f470",
   "metadata": {},
   "source": [
    "# 1. Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e12ef8e1113112",
   "metadata": {},
   "source": [
    "## 1.1. Crawl data from Airbnb"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In my project, I use Selenium instead of request and Beautifulsoup because Airbnb use Javascript and API to render the page. I need to use Selenium to open the page and get the data.",
   "id": "3b2c8de3b103e68f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81d4009aba0d4f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:51:16.673976Z",
     "start_time": "2024-05-28T02:51:16.672439Z"
    }
   },
   "source": [
    "# I use 4 threads to crawl data\n",
    "# 1 page has 15 listings, instead of opening Chrome window 18 times, I use multithreading to open 4 Chrome windows at the same time.\n",
    "semaphore = threading.Semaphore(4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a0396945aa2234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:51:16.676713Z",
     "start_time": "2024-05-28T02:51:16.674546Z"
    }
   },
   "source": [
    "# Function use to get all listing url in 1 page. Normally, 1 page has 18 listings.\n",
    "def get_url_list(url):\n",
    "    driver = webdriver.Chrome(service=cService)\n",
    "    driver.get(url)\n",
    "\n",
    "    craw_list = []\n",
    "\n",
    "    divs = driver.find_elements(by='class name', value='c4mnd7m')\n",
    "    for div in divs:\n",
    "        craw_dict = dict()\n",
    "        url = div.find_element(by=\"tag name\", value=\"a\").get_attribute('href')\n",
    "        price = div.find_element(by='class name', value='pquyp1l').text\n",
    "        craw_dict['URL'] = url\n",
    "        craw_dict['Price'] = price\n",
    "        craw_list.append(craw_dict)\n",
    "    driver.close()\n",
    "\n",
    "    return craw_list"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d1b48ad62a0aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:51:16.683247Z",
     "start_time": "2024-05-28T02:51:16.678115Z"
    }
   },
   "source": [
    "# Using url finding above to get all listing in 1 page\n",
    "# This function will get all information of each listing and save to a DataFrame\n",
    "def get_listings(url):\n",
    "    semaphore.acquire()\n",
    "    try:\n",
    "        listings = pd.DataFrame(\n",
    "            columns=['URL', 'Title', 'checkin_date', 'Price', 'Area', 'Avg_Rating', 'IsFavorite', 'host_info', 'host_url', 'host_name', 'host_rating', 'features', 'Cleanliness', 'Accuracy', 'Checkin', 'Communication', 'Location', 'Value'])\n",
    "        \n",
    "        u = url['URL'] + '&translate_ugc=false'\n",
    "    \n",
    "        parsed_url = urlparse(u)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        check_in_date = query_params.get('check_in', [None])[0]\n",
    "        \n",
    "        driver = webdriver.Chrome(service=cService)\n",
    "        driver.implicitly_wait(3)\n",
    "        driver.get(u)\n",
    "\n",
    "\n",
    "        title = driver.find_element(by=\"class name\", value=\"_1xxgv6l\").text\n",
    "    \n",
    "        try:\n",
    "            ratings = driver.find_elements(by='class name', value='l925rvg')\n",
    "            Cleanliness = ratings[0].text\n",
    "            Accuracy = ratings[1].text\n",
    "            Checkin = ratings[2].text\n",
    "            Communication = ratings[3].text\n",
    "            Location = ratings[4].text\n",
    "            Value = ratings[5].text\n",
    "        except:\n",
    "            Cleanliness = \"No Rating\"\n",
    "            Accuracy = \"No Rating\"\n",
    "            Checkin = \"No Rating\"\n",
    "            Communication = \"No Rating\"\n",
    "            Location = \"No Rating\"\n",
    "            Value = \"No Rating\"\n",
    "    \n",
    "        divs = driver.find_elements(by='class name', value='lgx66tx')\n",
    "        features = divs[0].text\n",
    "        host_info = divs[1].text\n",
    "        \n",
    "        try:\n",
    "            areas = driver.find_element(by='class name', value='_leqb4t').text\n",
    "        except:\n",
    "            areas = driver.find_element(by='class name', value='_152qbzi').text\n",
    "    \n",
    "        try:\n",
    "            avg_rating = driver.find_element(by='class name', value='gvcwa6y').text\n",
    "            isFavorite = \"Guest Favorite\"\n",
    "        except Exception as e1:\n",
    "            try:\n",
    "                avg_rating = driver.find_element(by='class name', value='r1lutz1s').text\n",
    "                isFavorite = \"Not Guest Favorite\"\n",
    "            except Exception as e2:\n",
    "                avg_rating = \"No Rating\"\n",
    "                isFavorite = \"\"\n",
    "\n",
    "        hosts = driver.find_elements(by='class name', value='colzjmk')\n",
    "        for host in hosts:\n",
    "            host_url = host.find_element(by=\"tag name\", value=\"a\").get_attribute('href')\n",
    "            \n",
    "        driver.close()\n",
    "        \n",
    "        driver2 = webdriver.Chrome(service=cService)\n",
    "        driver2.implicitly_wait(3)\n",
    "        driver2.get(host_url)\n",
    "\n",
    "        host_name = driver2.find_element(by=\"class name\", value=\"t1gpcl1t\").text\n",
    "        try:\n",
    "            host_rating = driver2.find_element(by=\"class name\", value=\"ruujrrq\").text\n",
    "        except:\n",
    "            host_rating = None\n",
    "        \n",
    "        driver2.close()\n",
    "\n",
    "        listings = listings._append({\n",
    "            'URL': u,\n",
    "            'Title': title,\n",
    "            'checkin_date': check_in_date,\n",
    "            'Price': url['Price'],\n",
    "            'Area': areas,\n",
    "            'Avg_Rating': avg_rating,\n",
    "            'IsFavorite': isFavorite,\n",
    "            'features': features,\n",
    "            'Cleanliness': Cleanliness,\n",
    "            'Accuracy': Accuracy,\n",
    "            'Checkin': Checkin,\n",
    "            'Communication': Communication,\n",
    "            'Location': Location,\n",
    "            'Value': Value,\n",
    "            'host_info': host_info,\n",
    "            'host_url': host_url,\n",
    "            'host_name': host_name,\n",
    "            'host_rating': host_rating\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "        with results_lock:\n",
    "            results.append(listings)\n",
    "    finally:\n",
    "        semaphore.release()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a50169459ba13e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:51:16.685755Z",
     "start_time": "2024-05-28T02:51:16.683835Z"
    }
   },
   "source": [
    "# Using the above function to get all listings in 1 page\n",
    "# This function use to split the work to multiple threads\n",
    "def crawl_and_collect(urls):\n",
    "    threads = []\n",
    "\n",
    "    for url in urls:\n",
    "        thread = threading.Thread(target=get_listings, args=(url,))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "        \n",
    "    df = pd.concat(results, ignore_index=True)\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de4cb9f2cc0ee8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:51:16.688459Z",
     "start_time": "2024-05-28T02:51:16.686202Z"
    }
   },
   "source": [
    "# Because the url of each page does not have same pattern, each page has unique id, I cannot use loop to get all pages from the constant url.\n",
    "# At the end of the page, there is page number and next button.\n",
    "# The next button use to detect that there is next page or not.\n",
    "# If there is next page, the function will get the next page url and call itself again.\n",
    "def find_next_page(url, list_next_page):\n",
    "    if url == None:\n",
    "        return list_next_page\n",
    "    \n",
    "    list_next_page.append(url)\n",
    "    \n",
    "    driver = webdriver.Chrome(service=cService)\n",
    "    driver.implicitly_wait(3)\n",
    "    driver.get(url)\n",
    "\n",
    "    buttonSpace = driver.find_element(by='class name', value='p1j2gy66')\n",
    "    buttonSingle = buttonSpace.find_elements(by='class name', value='l1ovpqvx')\n",
    "    for button in buttonSingle:\n",
    "        if button.get_attribute('aria-label') == \"Next\":\n",
    "            nextUrl = button.get_attribute('href')\n",
    "            driver.close()\n",
    "            find_next_page(nextUrl, list_next_page)\n",
    "            \n",
    "    return list_next_page"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af40f4335636aa49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:51:16.691098Z",
     "start_time": "2024-05-28T02:51:16.688990Z"
    }
   },
   "source": [
    "# Get all listings in 1 page and merge it as a DataFrame, then save it to a parquet file as historical data, which can be used for analysis later.\n",
    "# Or if the data have been transformed in the wrong way, we can use this data to re-transform.\n",
    "def crawler(url, count):\n",
    "    if url == None:\n",
    "        return\n",
    "    \n",
    "    global results\n",
    "    results = []\n",
    "    global results_lock\n",
    "    results_lock = threading.Lock()\n",
    "    \n",
    "    url_list = get_url_list(url)\n",
    "    \n",
    "    df_results = crawl_and_collect(url_list)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    year = now.year\n",
    "    month = now.month\n",
    "    day = now.day\n",
    "\n",
    "    outdir = f'./staging/{year}/{month}/{day}/'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "        \n",
    "    # I choose to use parquet file because it is faster than csv file and optimize for columnar storage.\n",
    "    df_results.to_parquet(outdir + f'page{count}.parquet', engine='pyarrow')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8b6e1d4f23216782",
   "metadata": {},
   "source": [
    "Demo method to get listing of page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be9b43eba0cdce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:52:07.261802Z",
     "start_time": "2024-05-28T02:51:16.691531Z"
    }
   },
   "source": [
    "page_1 = \"https://www.airbnb.co.nz/s/New-Zealand/homes?tab_id=home_tab&flexible_trip_lengths%5B%5D=one_week&monthly_start_date=2024-06-01&monthly_length=3&monthly_end_date=2024-09-01&price_filter_input_type=0&channel=EXPLORE&query=New%20Zealand&place_id=ChIJh5Z3Fw4gLG0RM0dqdeIY1rE&location_bb=weg99sMvjGvCU0cVQyWOaw%3D%3D&date_picker_type=calendar&adults=1&source=structured_search_input_header&search_type=autocomplete_click\"\n",
    "\n",
    "crawler(page_1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fab2ca8dca84cc18",
   "metadata": {},
   "source": [
    "![Demo](/Users/benminh1201/Downloads/SCR-20240528-nfbk.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15174b69c684567",
   "metadata": {},
   "source": [
    "page_1 = \"https://www.airbnb.co.nz/s/New-Zealand/homes?tab_id=home_tab&flexible_trip_lengths%5B%5D=one_week&monthly_start_date=2024-06-01&monthly_length=3&monthly_end_date=2024-09-01&price_filter_input_type=0&channel=EXPLORE&query=New%20Zealand&place_id=ChIJh5Z3Fw4gLG0RM0dqdeIY1rE&location_bb=weg99sMvjGvCU0cVQyWOaw%3D%3D&date_picker_type=calendar&adults=1&source=structured_search_input_header&search_type=autocomplete_click\"\n",
    "\n",
    "list_next_page = find_next_page(page_1, [])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7a5f986be9db1ae2",
   "metadata": {},
   "source": "In order to save time of running get url of all pages, I save it to a csv file at the first running, which can use to run the function later."
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c70a1b25362eda5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:57:50.290157Z",
     "start_time": "2024-05-28T02:57:50.275200Z"
    }
   },
   "source": [
    "list_next_page = pd.read_csv('staging/2024/5/26/list_next_page.csv')['0'].tolist()\n",
    "list_next_page"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "899b7fa42658074e",
   "metadata": {},
   "source": [
    "I split it to run in 3 times. Because I need to change VPN to access the website after I crawl many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d86b80c022af21",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for url in list_next_page[:5]:\n",
    "    count += 1\n",
    "    crawler(url, count)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac15679821f391c",
   "metadata": {},
   "source": [
    "for url in list_next_page[5:11]:\n",
    "    count += 1\n",
    "    crawler(url, count)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d0ac6bbcc414d",
   "metadata": {},
   "source": [
    "for url in list_next_page[11:]:\n",
    "    count += 1\n",
    "    crawler(url, count)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d6e078888dc10840",
   "metadata": {},
   "source": [
    "After running the function, I have full 15 pages in staging layer which save raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df77fdefc9ae8b",
   "metadata": {},
   "source": [
    "![listfile](/Users/benminh1201/Downloads/SCR-20240528-nhxh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86e1aac49bf444",
   "metadata": {},
   "source": [
    "## 1.2. Crawl weather data from api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a96a28963abf0c",
   "metadata": {},
   "source": "I only get the weather data of city and date, which is the same as the checkin date and area of the listing. So the csv file here is the data which is transformed in the Data Wrangling step. The weather data which I got is the date of the previous year of the checkin date."
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f667f75e5796b640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:02:13.887230Z",
     "start_time": "2024-05-28T03:02:13.816558Z"
    }
   },
   "source": [
    "# There can be the listing which has the same checkin date and city, so I need to drop duplicates.\n",
    "df = pd.read_csv('foudation/listings.csv')\n",
    "list_area = df[['Area', 'checkin_date']].copy().drop_duplicates(subset=['Area', 'checkin_date'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf91b4665e49768d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:02:15.515111Z",
     "start_time": "2024-05-28T03:02:15.491918Z"
    }
   },
   "source": [
    "# I get the weather in city and date of the previous year of the checkin date.\n",
    "list_area['checkin_date'] = pd.to_datetime(list_area['checkin_date'])\n",
    "list_area['fake_checkin_date'] =  list_area['checkin_date'] - pd.DateOffset(years=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cec50cea76c37b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:02:17.582319Z",
     "start_time": "2024-05-28T03:02:17.571366Z"
    }
   },
   "source": [
    "def get_weather(city, date):\n",
    "    response = requests.request(\"GET\", f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{city}/{date}?unitGroup=metric&include=days&key=GKHM62FQSWEDNTBQEQJ3M2UBC&contentType&contentType=json\")\n",
    "    if response.status_code!=200:\n",
    "        return {\n",
    "            'tempmax': None,\n",
    "            'tempmin': None,\n",
    "            'temp': None,\n",
    "            'humidity': None,\n",
    "            'main': None\n",
    "        }\n",
    "\n",
    "    result = json.loads(response.content)\n",
    "    return {\n",
    "        'tempmax': result['days'][0]['tempmax'],\n",
    "        'tempmin': result['days'][0]['tempmin'],\n",
    "        'temp': result['days'][0]['temp'],\n",
    "        'humidity': result['days'][0]['humidity'],\n",
    "        'main': result['days'][0]['icon']\n",
    "    }"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a770a86326629c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:02:25.009138Z",
     "start_time": "2024-05-28T03:02:23.905908Z"
    }
   },
   "source": [
    "# Demo of function\n",
    "get_weather('Auckland', '2023-01-12')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b46e420109c88580",
   "metadata": {},
   "source": [
    "Link of api: https://www.visualcrossing.com/"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I find the weather of the previous year of the checkin date.",
   "id": "1b0275b0bf6343a5"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1931199e51ebd3f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:07:18.420229Z",
     "start_time": "2024-05-28T03:05:18.460519Z"
    }
   },
   "source": [
    "list_area['weather'] = list_area.apply(lambda x: get_weather(x['Area'], x['fake_checkin_date'].strftime('%Y-%m-%d')), axis=1)\n",
    "list_area"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b556d35f5e1c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:08:18.534295Z",
     "start_time": "2024-05-28T03:08:18.506550Z"
    }
   },
   "source": [
    "# Splitting the dictionary to columns, then save to a parquet file.\n",
    "list_area = list_area.join(pd.json_normalize(list_area['weather']))\n",
    "list_area"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "792a4ee106f55338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:08:30.767926Z",
     "start_time": "2024-05-28T03:08:30.741611Z"
    }
   },
   "source": [
    "now = datetime.now()\n",
    "year = datetime.now().year\n",
    "month = datetime.now().month\n",
    "day = datetime.now().day\n",
    "\n",
    "list_area.to_parquet(f'./staging/{year}/{month}/{day}/weather.parquet', engine='pyarrow')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "13d1d1d7e1ddf7b3",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73382e023a478b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:11:14.473359Z",
     "start_time": "2024-05-28T03:11:14.419599Z"
    }
   },
   "source": [
    "path = f'staging/2024/5/26/'\n",
    "all_files = glob.glob(os.path.join(path, \"*.parquet\"))\n",
    "df_list = [pd.read_parquet(file) for file in all_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c54d577454d9dbc8",
   "metadata": {},
   "source": [
    "There are 269 listings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27544a7bc4ce9564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:07.906378Z",
     "start_time": "2024-05-28T03:14:07.878841Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a784ebd5a4954e33",
   "metadata": {},
   "source": [
    "### 2.2. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d077b416b3a5ee",
   "metadata": {},
   "source": [
    "#### 2.2.1 Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca3c2f8f9c3822",
   "metadata": {},
   "source": [
    "There are 3 columns related to price: OriginalPrice, DiscountPrice, and TotalPrice. We will split the Price column into 3 columns: OriginalPrice, DiscountPrice, and TotalPrice (Price for 5 days). We will also remove the currency symbol and convert the price to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134b179012c00123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:22.201297Z",
     "start_time": "2024-05-28T03:14:22.169003Z"
    }
   },
   "source": [
    "df['OriginalPrice'] = df['Price'].str.split('\\n', expand=True)[0].replace('', None)\n",
    "df['DiscountPrice'] = df['Price'].str.split('\\n', expand=True)[1]\n",
    "df['TotalPrice'] = df['Price'].str.split('\\n', expand=True)[5]\n",
    "df.drop(columns=['Price'], inplace=True)\n",
    "df.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26911b642ba10b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:25.747673Z",
     "start_time": "2024-05-28T03:14:25.721792Z"
    }
   },
   "source": [
    "df['DiscountPrice'] = df['DiscountPrice'].replace('night', None)\n",
    "df['DiscountPrice'] = df['DiscountPrice'].str.replace('$', '').str.replace(' NZD', '').astype(float)\n",
    "\n",
    "df['OriginalPrice'] = df['OriginalPrice'].str.replace('$', '').str.replace(' NZD', '').astype(float)\n",
    "\n",
    "df['TotalPrice'] = df['TotalPrice'].str.split(' ', expand=True)[0]\n",
    "df['TotalPrice'] = df['TotalPrice'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "df.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4beb2882b3ac3488",
   "metadata": {},
   "source": [
    "#### 2.2.2 Area"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I only keep the city name in the Area column. There are some listings with the area name as 'NZ' or 'Au', which I will replace with 'Auckland'.",
   "id": "48b874120795575a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eed042086160773e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:26.238414Z",
     "start_time": "2024-05-28T03:14:26.210660Z"
    }
   },
   "source": [
    "df['Area'] = df['Area'].str.split(', ').apply(lambda x: x[-2])\n",
    "df['Area'] = df['Area'].replace('NZ', 'Auckland')\n",
    "df['Area'] = df['Area'].replace('Au', 'Auckland')\n",
    "df.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "42cf2697ddc07ef1",
   "metadata": {},
   "source": [
    "#### 2.2.3 Average Rating"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I split the rating from the sentence and convert it to float. Some listings have a new rating, which I will replace with -1.",
   "id": "28c259a579bcfb89"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe1febc686a248b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:27.820931Z",
     "start_time": "2024-05-28T03:14:27.798568Z"
    }
   },
   "source": [
    "df['Avg_Rating'] = df['Avg_Rating'].str.replace('New', '-1')\n",
    "df['Avg_Rating'] = df['Avg_Rating'].str.split(' ').apply(lambda x: x[1] if len(x) > 1 else x[0]).astype(float)\n",
    "df.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "839c6f88c73ff2c9",
   "metadata": {},
   "source": [
    "#### 2.2.4 Host Information"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The original host_info contains the host type (Superhost) and hosting time. I will split this column into 2 columns: hosting_type and hosting_time. I will also convert the host_rating to float.",
   "id": "5e591f65ed934302"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c65507750047c56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:28.873271Z",
     "start_time": "2024-05-28T03:14:28.843470Z"
    }
   },
   "source": [
    "df['host_info'] = df['host_info'].apply(lambda x: \"None · \" + x if \"·\" not in x else x)\n",
    "df['hosting_type'] = df['host_info'].str.split('·', expand=True)[0].str.strip()\n",
    "df['hosting_time'] = df['host_info'].str.split('·', expand=True)[1]\n",
    "df['host_rating'] = df['host_rating'].astype(float)\n",
    "df.drop(columns=['host_info'], inplace=True)\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "85da4f7b1cdcff5b",
   "metadata": {},
   "source": [
    "#### 2.2.5 Rating"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "On Airbnb, there are 6 types of ratings: cleanliness, accuracy, check-in, communication, location, and value. I will split the rating from the sentence and convert it to float.",
   "id": "5bf89a3fa256854f"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc752a0282c1b8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:29.954901Z",
     "start_time": "2024-05-28T03:14:29.921938Z"
    }
   },
   "source": [
    "df['Cleanliness'] = df['Cleanliness'].str.split('\\n').apply(lambda x: x[-1] if len(x) > 1 else None).astype(float)\n",
    "df['Accuracy'] = df['Accuracy'].str.split('\\n').apply(lambda x: x[-1] if len(x) > 1 else None).astype(float)\n",
    "df['Checkin'] = df['Checkin'].str.split('\\n').apply(lambda x: x[-1] if len(x) > 1 else None).astype(float)\n",
    "df['Communication'] = df['Communication'].str.split('\\n').apply(lambda x: x[-1] if len(x) > 1 else None).astype(float)\n",
    "df['Location'] = df['Location'].str.split('\\n').apply(lambda x: x[-1] if len(x) > 1 else None).astype(float)\n",
    "df['Value'] = df['Value'].str.split('\\n').apply(lambda x: x[-1] if len(x) > 1 else None).astype(float)\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fe8760fb89181b75",
   "metadata": {},
   "source": [
    "#### 2.2.6 Features"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The features of each listing are in different formats. This listing may have this feature and may not have other feature. Thus,  I need to find the unique features and keep only the features that are common in most listings.",
   "id": "610451b0141e97f1"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fb682d7d4de4c5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:32.117620Z",
     "start_time": "2024-05-28T03:14:32.094544Z"
    }
   },
   "source": [
    "df['features'] = (df['features']\n",
    "                  .str.replace('beds', 'bed')\n",
    "                  .str.replace('bedrooms', 'bedroom')\n",
    "                  .str.replace('baths', 'bath')\n",
    "                  .str.replace('guests', 'guest'))\n",
    "df_temp = df['features'].str.split('·', expand=True).melt()\n",
    "df_temp"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "43b6585c3e90969f",
   "metadata": {},
   "source": [
    "Because the data of feaures column does not have a consistent format, I reshape the data to 1 column to find the unique feature by using regex to remove the number in string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f61bb5e896f86",
   "metadata": {},
   "source": [
    "The features can have \"1 bath\" or \"1.5 baths\", so I use regex to remove the number in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6527936ed80697c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:34.709211Z",
     "start_time": "2024-05-28T03:14:34.692961Z"
    }
   },
   "source": [
    "df_temp['value'].replace('\\d+\\.?\\d*', '', regex=True).str.strip().value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f0fe2163a4136eb6",
   "metadata": {},
   "source": [
    "From the above table, we can see that the features which account for most of the data is number of guest, bath, bedroom and bed. Thus, I only keep these features. I also keep the studio option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95bc66e5b3c58296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:35.679555Z",
     "start_time": "2024-05-28T03:14:35.637356Z"
    }
   },
   "source": [
    "def extract_details(details):\n",
    "    parts = details.split(' · ')\n",
    "    guest, bath, bed, bedroom, studio = None, None, None, None, 0\n",
    "\n",
    "    for part in parts:\n",
    "        if 'guest' in part:\n",
    "            guest = float(part.split(' ')[0])\n",
    "        elif 'bath' in part and 'Half' not in part and 'shared' not in part and 'Shared' not in part and 'private' not in part and 'Private' not in part and 'Dedicated' not in part:\n",
    "            bath = float(part.split(' ')[0])\n",
    "        elif 'bedroom' in part:\n",
    "            bedroom = float(part.split(' ')[0])\n",
    "        elif 'bed' in part:\n",
    "            bed = float(part.split(' ')[0])\n",
    "        elif 'Studio' in part:\n",
    "            studio = 1\n",
    "\n",
    "    return guest, bath, bed, bedroom, studio\n",
    "\n",
    "df[['guest', 'bath', 'bed', 'bedroom', 'studio']]= df['features'].apply(lambda x: pd.Series(extract_details(x)))\n",
    "df.drop(columns=['features'], inplace=True)\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "de179d258723b309",
   "metadata": {},
   "source": "#### 2.2.7 Hosting time"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6ea1f7f68d6e99e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:38.817610Z",
     "start_time": "2024-05-28T03:14:38.804534Z"
    }
   },
   "source": [
    "df[df['hosting_time'].str.contains('month')]['hosting_time']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "81322a4942ec9618",
   "metadata": {},
   "source": [
    "Because the data has both year and month, I will convert month to year by dividing by 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "522dafcb1647d111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:46.162003Z",
     "start_time": "2024-05-28T03:14:46.149502Z"
    }
   },
   "source": [
    "df['hosting_time'] = df['hosting_time'].str.replace('hosting', '').str.strip()\n",
    "\n",
    "def transform_duration(time):\n",
    "    years = 0\n",
    "    months = 0\n",
    "\n",
    "    if 'New Host' in time:\n",
    "        return 0\n",
    "    if 'year' in time:\n",
    "        years = int(time.split(' ')[0])\n",
    "    if 'month' in time:\n",
    "        months_str = time.split(' ')[0]\n",
    "        months = int(months_str) / 12\n",
    "\n",
    "    return years + months\n",
    "\n",
    "df['hosting_time'] = df['hosting_time'].apply(transform_duration)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6b42fd4b2a6734e8",
   "metadata": {},
   "source": [
    "#### 2.2.8 Get listing and host ID"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I assume that the sequence number in the URL is the unique id",
   "id": "f873111f2d454473"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d4b8a267a65c5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:47.437753Z",
     "start_time": "2024-05-28T03:14:47.429703Z"
    }
   },
   "source": [
    "df['host_id'] = df['host_url'].str.split('/', expand=True)[5]\n",
    "df['listing_id'] = df['URL'].str.split('/', expand=True)[4].str.split('?', expand=True)[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "77eb20e1df8673a8",
   "metadata": {},
   "source": "Save transformed data to a csv file. In assignment 3, I will use this csv file to insert to SQlite database."
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75078ad8498e0fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:53.441255Z",
     "start_time": "2024-05-28T03:14:53.423443Z"
    }
   },
   "source": [
    "df.to_csv('foudation/listings.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddaaa69030d7d4c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:14:53.889747Z",
     "start_time": "2024-05-28T03:14:53.858613Z"
    }
   },
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the step 1.2, I have already transformed the weather data, so I will use it to merge with the listing data.",
   "id": "257c99209ea02a34"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd3e800faf015cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:18:02.805434Z",
     "start_time": "2024-05-28T03:18:02.766305Z"
    }
   },
   "source": [
    "df_weather = pd.read_parquet('staging/2024/5/26/weather.parquet')\n",
    "df_weather"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da3c761b353f15ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:19:54.484375Z",
     "start_time": "2024-05-28T03:19:54.472942Z"
    }
   },
   "source": [
    "df['checkin_date'] = pd.to_datetime(df['checkin_date'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33d4e9d0b860bc4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:19:57.219154Z",
     "start_time": "2024-05-28T03:19:57.197701Z"
    }
   },
   "source": [
    "df_full = pd.merge(df, df_weather, on=['Area', 'checkin_date'], how='left')\n",
    "df_full.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c95f33b986a88b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:20:06.346248Z",
     "start_time": "2024-05-28T03:20:06.317590Z"
    }
   },
   "source": [
    "df_full"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b6e877fd12b0aaba",
   "metadata": {},
   "source": [
    "### 2.3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81384626cead9b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:21:59.109219Z",
     "start_time": "2024-05-28T03:21:58.775462Z"
    }
   },
   "source": [
    "feq=df['Area'].value_counts().sort_values(ascending=True)\n",
    "feq.plot.barh(figsize=(8, 8), width=0.8)\n",
    "plt.title(\"Number of listings by Area\", fontsize=20)\n",
    "plt.xlabel('Number of listings', fontsize=12)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1ca0bce0bab4fc17",
   "metadata": {},
   "source": [
    "The most listings are in Waikato, followed by Auckland and Northland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd8c7253d0c35d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:22:12.988862Z",
     "start_time": "2024-05-28T03:22:12.866448Z"
    }
   },
   "source": [
    "feq=df['guest'].value_counts().sort_index()\n",
    "feq.plot.bar(figsize=(10, 8), color='b', width=0.8, rot=0)\n",
    "plt.title(\"Maximum guest per listings\", fontsize=20)\n",
    "plt.ylabel('Number of listings', fontsize=12)\n",
    "plt.xlabel('Accommodates', fontsize=12)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7abf38cc2271ae46",
   "metadata": {},
   "source": [
    "Most of the listings allow maximum 2 guests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aef2f68adc8646b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:22:18.827806Z",
     "start_time": "2024-05-28T03:22:18.627981Z"
    }
   },
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "feq=df['bath'].value_counts().sort_index()\n",
    "feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.ylabel('Number of listings', fontsize=12)\n",
    "plt.title('Number of bath per listings')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "feq=df['bed'].value_counts().sort_index()\n",
    "feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.ylabel('Number of listings', fontsize=12)\n",
    "plt.title('Number of bed per listings')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "feq=df['bedroom'].value_counts().sort_index()\n",
    "feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.ylabel('Number of listings', fontsize=12)\n",
    "plt.title('Number of bathroom per listings')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c58a4d2fc6fa5c64",
   "metadata": {},
   "source": [
    "There is typically one bedroom, one bathroom, and one bed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9441b508322a172e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:22:39.686846Z",
     "start_time": "2024-05-28T03:22:39.594110Z"
    }
   },
   "source": [
    "feq=df['studio'].value_counts().sort_index()\n",
    "feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.ylabel('Number of listings', fontsize=12)\n",
    "plt.title('Distribution of Studio and Non-Studio Listings')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "366e8fd476c8df3",
   "metadata": {},
   "source": [
    "Not many listings has the studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bbe9a50fe3e0063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:24:54.530473Z",
     "start_time": "2024-05-28T03:24:54.402457Z"
    }
   },
   "source": [
    "plt.hist(df['Avg_Rating'], color='b')\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlabel('Average rating', fontsize=12)\n",
    "plt.title(\"Histogram of Average rating\", fontsize=12)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7665ea4c5b3e8c73",
   "metadata": {},
   "source": [
    "Most of the ratings are between 3.8 to 5. Minus 1 rating is the new listing."
   ]
  },
  {
   "cell_type": "code",
   "id": "82e235248b39ee0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T04:42:17.188329Z",
     "start_time": "2024-05-28T04:42:16.994075Z"
    }
   },
   "source": [
    "feq = df.groupby('Area')['TotalPrice'].mean().sort_values(ascending=True)\n",
    "feq.plot.barh(figsize=(8, 8), color='b', width=0.8)\n",
    "plt.title(\"Average 5-night price for 1-person accommodation\", fontsize=20)\n",
    "plt.xlabel('Average 5-night price (NZD)', fontsize=12)\n",
    "plt.show()"
   ],
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "252271e88315d25a",
   "metadata": {},
   "source": [
    "Because the default number of guests when I crawl the data is for 1 adult in 5 nights. Thus, the price is for 1 person.\n",
    "On average, the price is the highest in Otago, followed by Marlborough Sounds and Golden Bay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3e0709c17336400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:25:23.521171Z",
     "start_time": "2024-05-28T03:25:22.975143Z"
    }
   },
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "\n",
    "ax1 = fig.add_subplot(321)\n",
    "feq=df['Location'].value_counts().sort_index()\n",
    "ax1=feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "#ax1.tick_params(axis = 'both', labelsize = 16)\n",
    "plt.title(\"Location\", fontsize=24)\n",
    "plt.ylabel('Number of listings', fontsize=14)\n",
    "plt.xlabel('Average review score', fontsize=14)\n",
    "\n",
    "ax2 = fig.add_subplot(322)\n",
    "feq=df['Cleanliness'].value_counts().sort_index()\n",
    "ax2=feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.title(\"Cleanliness\", fontsize=24)\n",
    "plt.ylabel('Number of listings', fontsize=14)\n",
    "plt.xlabel('Average review score', fontsize=14)\n",
    "\n",
    "ax3 = fig.add_subplot(323)\n",
    "feq=df['Value'].value_counts().sort_index()\n",
    "ax3=feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.title(\"Value\", fontsize=24)\n",
    "plt.ylabel('Number of listings', fontsize=14)\n",
    "plt.xlabel('Average review score', fontsize=14)\n",
    "\n",
    "ax4 = fig.add_subplot(324)\n",
    "feq=df['Communication'].value_counts().sort_index()\n",
    "ax4=feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.title(\"Communication\", fontsize=24)\n",
    "plt.ylabel('Number of listings', fontsize=14)\n",
    "plt.xlabel('Average review score', fontsize=14)\n",
    "\n",
    "ax5 = fig.add_subplot(325)\n",
    "feq=df['Checkin'].value_counts().sort_index()\n",
    "ax5=feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.title(\"Arrival\", fontsize=24)\n",
    "plt.ylabel('Number of listings', fontsize=14)\n",
    "plt.xlabel('Average review score', fontsize=14)\n",
    "\n",
    "ax6 = fig.add_subplot(326)\n",
    "feq=df['Accuracy'].value_counts().sort_index()\n",
    "ax6=feq.plot.bar(color='b', width=0.8, rot=0)\n",
    "plt.title(\"Accuracy\", fontsize=24)\n",
    "plt.ylabel('Number of listings', fontsize=14)\n",
    "plt.xlabel('Average review score', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "38e9f775e032f495",
   "metadata": {},
   "source": [
    "Similar to the overall rating, most of the ratings are between larger than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd5dcb10b8ace755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:25:31.920773Z",
     "start_time": "2024-05-28T03:25:31.772432Z"
    }
   },
   "source": [
    "# Create the first subplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "feq=df['hosting_type'].value_counts()\n",
    "feq.plot.bar(width=0.8, rot=0)\n",
    "plt.title(\"Number of listings with Superhost\", fontsize=20)\n",
    "plt.ylabel('Number of listings', fontsize=12)\n",
    "\n",
    "# Create the second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "feq=df['IsFavorite'].value_counts()\n",
    "feq.plot.bar(width=0.8, rot=0)\n",
    "plt.title(\"Number of listings with Guest Favorite\", fontsize=20)\n",
    "plt.ylabel('Number of listings', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7ccd33d8f0c06328",
   "metadata": {},
   "source": [
    "There is 2 kind of host: Superhost and Regular host, and Guest favorite or not. Overall, Superhost and Guest Favorite are more than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f04546f7a049305e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:25:50.572407Z",
     "start_time": "2024-05-28T03:25:50.386507Z"
    }
   },
   "source": [
    "feq=df[['host_id', 'host_name']].value_counts().sort_values(ascending=False)[:20]\n",
    "feq\n",
    "feq.plot.bar(width=0.8, rot=90)\n",
    "plt.title(\"Number of listings per host\", fontsize=20)\n",
    "plt.ylabel('Number of listings', fontsize=12)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2af0266b272e3a6f",
   "metadata": {},
   "source": [
    "Because the data is only show the first or last name of the host, so I need to group by id and name.\n",
    "Daniel is the host with the most listings, with 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ec027c72a61056",
   "metadata": {},
   "source": [
    "### 2.4. Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "257cd3fc51525bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:27:07.463554Z",
     "start_time": "2024-05-28T03:27:06.743920Z"
    }
   },
   "source": [
    "msno.bar(df, color='b')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3d9953c0b802f2fe",
   "metadata": {},
   "source": [
    "The Discount price has the most missing values, because not all listings have discount price. I fill the missing values with the original price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb381dd97506db33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:27:17.125763Z",
     "start_time": "2024-05-28T03:27:17.103476Z"
    }
   },
   "source": [
    "df['DiscountPrice'] = df['DiscountPrice'].fillna(df['OriginalPrice'])\n",
    "df['guest'] = df['guest'].fillna(2)\n",
    "df['bath'] = df['bath'].fillna(df['guest'] / 2)\n",
    "df['bed'] = df['bed'].fillna(df['guest'] / 2)\n",
    "df['bedroom'] = df['bedroom'].fillna(df['guest'] / 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f6273cdd5c883c5",
   "metadata": {},
   "source": [
    "I assume that maximum guest for each listing is 2, so I fill the missing values of bath, bed, and bedroom with half of the maximum guest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4f3257667a22d",
   "metadata": {},
   "source": [
    "### 2.5. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13bc00034d88d09",
   "metadata": {},
   "source": [
    "#### Does the room features affect the price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43866db921d973f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:27:56.871132Z",
     "start_time": "2024-05-28T03:27:56.724925Z"
    }
   },
   "source": [
    "correlation_matrix = df[['OriginalPrice', 'bed', 'bedroom', 'bath', 'guest', 'studio']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9f83849416976b1",
   "metadata": {},
   "source": [
    "The price has a positive correlation with the number of maximum guest, beds, bedrooms, and bath, but a negative correlation with the number of studio. However, the correlation is not strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77c552b2da492697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:29:57.021508Z",
     "start_time": "2024-05-28T03:29:56.986966Z"
    }
   },
   "source": [
    "df_ols = df[['OriginalPrice', 'bed', 'bedroom', 'bath', 'guest', 'studio']].dropna()\n",
    "# Prepare the data\n",
    "X = df_ols[['bed', 'bedroom', 'bath', 'guest', 'studio']]\n",
    "y = df_ols['OriginalPrice']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "302ec818fb70675b",
   "metadata": {},
   "source": [
    "The R-squared value is 0.4, which means that the model explains 40% of the variance in the data.\n",
    "The number of bedrooms and bath are significant predictors of price, with more bedrooms and bathrooms associated with higher prices, because they have high positive coefficient and small p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f9ed2690e299e",
   "metadata": {},
   "source": [
    "#### Does the ratings of listing and host affect the price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1446d5f5ec9e9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:31:33.197224Z",
     "start_time": "2024-05-28T03:31:33.022691Z"
    }
   },
   "source": [
    "correlation_matrix2 = df[['OriginalPrice', 'Avg_Rating', 'host_rating', 'Cleanliness', 'Accuracy', 'Checkin', 'Communication', 'Location', 'Value']].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix2, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f4884061542b7207",
   "metadata": {},
   "source": [
    "Overall, the correlation of price with ratings is not strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "283dbe1bea3118e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:33:37.991147Z",
     "start_time": "2024-05-28T03:33:37.962815Z"
    }
   },
   "source": [
    "df_ols2 = df[['OriginalPrice', 'Avg_Rating', 'host_rating', 'Cleanliness', 'Accuracy', 'Checkin', 'Communication', 'Location', 'Value']].dropna()\n",
    "# Prepare the data\n",
    "X = df_ols2[['Avg_Rating', 'host_rating', 'Cleanliness', 'Accuracy', 'Checkin', 'Communication', 'Location', 'Value']]\n",
    "y = df_ols2['OriginalPrice']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "70eb53d5494077fb",
   "metadata": {},
   "source": [
    "The R-squared value is just 0.3. The important variable is Average Rating, Cleanliness, Location and Value with small p-value. However, we see the negative coefficient of Cleanliness and Value variables, which is not make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0b4bea9878e19",
   "metadata": {},
   "source": [
    "I convert the hosting type and guest favorite to binary variable, then use them to predict the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "729de1484b1c499f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:35:06.060046Z",
     "start_time": "2024-05-28T03:35:06.048825Z"
    }
   },
   "source": [
    "df['hosting_type_binary'] = df['hosting_type'].str.strip().apply(lambda x: 1 if x == 'Superhost' else 0)\n",
    "df['IsFavorite_binary'] = df['IsFavorite'].apply(lambda x: 1 if x == 'Guest Favorite' else 0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4facdd908c844c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:35:11.357502Z",
     "start_time": "2024-05-28T03:35:11.326899Z"
    }
   },
   "source": [
    "df_ols3 = df[['OriginalPrice', 'Avg_Rating', 'host_rating', 'Cleanliness', 'Accuracy', 'Checkin', 'Communication', 'Location', 'Value', 'hosting_type_binary', 'IsFavorite_binary', 'hosting_time']].dropna()\n",
    "# Prepare the data\n",
    "X = df_ols3[['Avg_Rating', 'host_rating', 'Cleanliness', 'Accuracy', 'Checkin', 'Communication', 'Location', 'Value', 'hosting_type_binary', 'IsFavorite_binary', 'hosting_time']]\n",
    "y = df_ols3['OriginalPrice']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a58d94fb0cae40cc",
   "metadata": {},
   "source": [
    "The R-squared is not increase. And we see most coefficient is negative, while all variables is rating, in real life, the higher rating should have higher price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d85e002040aca",
   "metadata": {},
   "source": [
    "#### Does weather affect the price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fa95c05be99582b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T03:49:24.677403Z",
     "start_time": "2024-05-28T03:49:24.537343Z"
    }
   },
   "source": [
    "correlation_matrix3 = df_full[['OriginalPrice', 'tempmax', 'tempmin', 'temp', 'humidity']].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix3, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec027ea7a4296b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T04:03:03.350564Z",
     "start_time": "2024-05-28T04:03:03.316107Z"
    }
   },
   "source": [
    "df_ols4 = df_full[['OriginalPrice', 'tempmax', 'tempmin', 'temp', 'humidity', 'main']].dropna()\n",
    "df_ols4 = pd.get_dummies(df_ols4, columns=['main'])\n",
    "# Prepare the data\n",
    "X = df_ols4[['tempmax', 'tempmin', 'temp', 'humidity', 'main_clear-day', 'main_cloudy', 'main_partly-cloudy-day', 'main_rain']]\n",
    "y = df_ols4['OriginalPrice']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X.astype(float)).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6e9f66e2de3fd",
   "metadata": {},
   "source": [
    "The clear day and partly cloudy day have high positive coefficient, which mean that the price is higher in these days. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
