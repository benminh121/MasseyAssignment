{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:09:20.078246Z",
     "start_time": "2024-05-01T03:09:20.061142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "id": "51fd87825c0e14e3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T03:06:47.153735Z",
     "start_time": "2024-05-01T03:06:47.143241Z"
    }
   },
   "source": [
    "male = ['Tom Holland', 'Robert Downey Jr', 'Jason Momoa', 'Hugh Jackman', 'Henry Cavil', 'Dwayne Johnson',\n",
    "        'Chris Pratt', 'Chris Hemsworth', 'Andy Samberg']"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:06:48.133815Z",
     "start_time": "2024-05-01T03:06:47.994809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = 'dataset/training_celeb20x20.csv'\n",
    "df = pd.read_csv(path, header=0)\n",
    "df.head(5)"
   ],
   "id": "b55dc5b5778cdb9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                celeb      r1c1      r1c2      r1c3      r1c4      r1c5  \\\n",
       "0  Alexandra Daddario  0.117725  0.098078  0.150353  0.161020  0.137333   \n",
       "1  Alexandra Daddario  0.799255  0.795843  0.137216  0.367725  0.517490   \n",
       "2  Alexandra Daddario  0.917922  0.915451  0.921216  0.591647  0.251098   \n",
       "3  Alexandra Daddario  0.187647  0.191569  0.161412  0.014824  0.073647   \n",
       "4  Alexandra Daddario  0.948392  0.878667  0.850627  0.777569  0.640000   \n",
       "\n",
       "       r1c6      r1c7      r1c8      r1c9  ...    r20c11    r20c12    r20c13  \\\n",
       "0  0.137882  0.089137  0.202824  0.154471  ...  0.309020  0.372824  0.153686   \n",
       "1  0.325882  0.093843  0.140667  0.043569  ...  0.564157  0.537804  0.589569   \n",
       "2  0.303216  0.259843  0.236078  0.175529  ...  0.554627  0.628392  0.537020   \n",
       "3  0.057961  0.022667  0.156000  0.203922  ...  0.669725  0.732471  0.750745   \n",
       "4  0.646392  0.724549  0.674745  0.572510  ...  0.356078  0.329882  0.281608   \n",
       "\n",
       "     r20c14    r20c15    r20c16    r20c17    r20c18    r20c19    r20c20  \n",
       "0  0.212118  0.169529  0.173294  0.609569  0.359922  0.427176  0.439961  \n",
       "1  0.541412  0.224000  0.063608  0.952706  0.863765  0.809137  0.788118  \n",
       "2  0.369490  0.266431  0.231882  0.204314  0.278667  0.283686  0.380941  \n",
       "3  0.759922  0.812000  0.745373  0.698039  0.601882  0.549765  0.457569  \n",
       "4  0.350000  0.243529  0.047922  0.090275  0.128863  0.072314  0.126941  \n",
       "\n",
       "[5 rows x 401 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celeb</th>\n",
       "      <th>r1c1</th>\n",
       "      <th>r1c2</th>\n",
       "      <th>r1c3</th>\n",
       "      <th>r1c4</th>\n",
       "      <th>r1c5</th>\n",
       "      <th>r1c6</th>\n",
       "      <th>r1c7</th>\n",
       "      <th>r1c8</th>\n",
       "      <th>r1c9</th>\n",
       "      <th>...</th>\n",
       "      <th>r20c11</th>\n",
       "      <th>r20c12</th>\n",
       "      <th>r20c13</th>\n",
       "      <th>r20c14</th>\n",
       "      <th>r20c15</th>\n",
       "      <th>r20c16</th>\n",
       "      <th>r20c17</th>\n",
       "      <th>r20c18</th>\n",
       "      <th>r20c19</th>\n",
       "      <th>r20c20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexandra Daddario</td>\n",
       "      <td>0.117725</td>\n",
       "      <td>0.098078</td>\n",
       "      <td>0.150353</td>\n",
       "      <td>0.161020</td>\n",
       "      <td>0.137333</td>\n",
       "      <td>0.137882</td>\n",
       "      <td>0.089137</td>\n",
       "      <td>0.202824</td>\n",
       "      <td>0.154471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309020</td>\n",
       "      <td>0.372824</td>\n",
       "      <td>0.153686</td>\n",
       "      <td>0.212118</td>\n",
       "      <td>0.169529</td>\n",
       "      <td>0.173294</td>\n",
       "      <td>0.609569</td>\n",
       "      <td>0.359922</td>\n",
       "      <td>0.427176</td>\n",
       "      <td>0.439961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexandra Daddario</td>\n",
       "      <td>0.799255</td>\n",
       "      <td>0.795843</td>\n",
       "      <td>0.137216</td>\n",
       "      <td>0.367725</td>\n",
       "      <td>0.517490</td>\n",
       "      <td>0.325882</td>\n",
       "      <td>0.093843</td>\n",
       "      <td>0.140667</td>\n",
       "      <td>0.043569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564157</td>\n",
       "      <td>0.537804</td>\n",
       "      <td>0.589569</td>\n",
       "      <td>0.541412</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.063608</td>\n",
       "      <td>0.952706</td>\n",
       "      <td>0.863765</td>\n",
       "      <td>0.809137</td>\n",
       "      <td>0.788118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexandra Daddario</td>\n",
       "      <td>0.917922</td>\n",
       "      <td>0.915451</td>\n",
       "      <td>0.921216</td>\n",
       "      <td>0.591647</td>\n",
       "      <td>0.251098</td>\n",
       "      <td>0.303216</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.236078</td>\n",
       "      <td>0.175529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0.628392</td>\n",
       "      <td>0.537020</td>\n",
       "      <td>0.369490</td>\n",
       "      <td>0.266431</td>\n",
       "      <td>0.231882</td>\n",
       "      <td>0.204314</td>\n",
       "      <td>0.278667</td>\n",
       "      <td>0.283686</td>\n",
       "      <td>0.380941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexandra Daddario</td>\n",
       "      <td>0.187647</td>\n",
       "      <td>0.191569</td>\n",
       "      <td>0.161412</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.057961</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.732471</td>\n",
       "      <td>0.750745</td>\n",
       "      <td>0.759922</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.745373</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.601882</td>\n",
       "      <td>0.549765</td>\n",
       "      <td>0.457569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexandra Daddario</td>\n",
       "      <td>0.948392</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>0.850627</td>\n",
       "      <td>0.777569</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.646392</td>\n",
       "      <td>0.724549</td>\n",
       "      <td>0.674745</td>\n",
       "      <td>0.572510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356078</td>\n",
       "      <td>0.329882</td>\n",
       "      <td>0.281608</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.047922</td>\n",
       "      <td>0.090275</td>\n",
       "      <td>0.128863</td>\n",
       "      <td>0.072314</td>\n",
       "      <td>0.126941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 401 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:07:19.880865Z",
     "start_time": "2024-05-01T03:07:19.856702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "y_gender = [1 if i in male else 0 for i in y]\n",
    "y_gender"
   ],
   "id": "b1b01924e63c3ffc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:10:07.526972Z",
     "start_time": "2024-05-01T03:10:07.504723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = Pipeline([\n",
    "    ('min_max_scaler', MinMaxScaler()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y_gender, test_size=0.3, random_state=42)"
   ],
   "id": "33ef5d749e24eea",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:10:08.445810Z",
     "start_time": "2024-05-01T03:10:08.434344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "\n",
    "    elif train == False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ],
   "id": "faba2f91c92ae75c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:11:32.870623Z",
     "start_time": "2024-05-01T03:11:32.267285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(loss='hinge', dual=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=False)"
   ],
   "id": "af0f126b17ea0164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 88.09%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.882123     0.879392  0.880891     0.880758      0.880863\n",
      "recall        0.898966     0.859796  0.880891     0.879381      0.880891\n",
      "f1-score      0.890465     0.869484  0.880891     0.879974      0.880783\n",
      "support    1257.000000  1077.000000  0.880891  2334.000000   2334.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1130  127]\n",
      " [ 151  926]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 78.72%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.785311    0.789362  0.787213     0.787336      0.787273\n",
      "recall       0.808140    0.764948  0.787213     0.786544      0.787213\n",
      "f1-score     0.796562    0.776963  0.787213     0.786762      0.787066\n",
      "support    516.000000  485.000000  0.787213  1001.000000   1001.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[417  99]\n",
      " [114 371]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benminh1201/miniconda3/envs/massey/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:11:49.713430Z",
     "start_time": "2024-05-01T03:11:48.346250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# The hyperparameter coef0 controls how much the model is influenced by high degree ploynomials \n",
    "model = SVC(kernel='poly', degree=2, gamma='auto', coef0=1, C=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=False)"
   ],
   "id": "8972728642ec6e99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 86.38%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.868814     0.857681  0.863753     0.863248      0.863677\n",
      "recall        0.879873     0.844940  0.863753     0.862406      0.863753\n",
      "f1-score      0.874308     0.851263  0.863753     0.862786      0.863674\n",
      "support    1257.000000  1077.000000  0.863753  2334.000000   2334.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1106  151]\n",
      " [ 167  910]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 81.22%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.809434    0.815287  0.812188     0.812360      0.812270\n",
      "recall       0.831395    0.791753  0.812188     0.811574      0.812188\n",
      "f1-score     0.820268    0.803347  0.812188     0.811807      0.812069\n",
      "support    516.000000  485.000000  0.812188  1001.000000   1001.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[429  87]\n",
      " [101 384]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:12:07.312922Z",
     "start_time": "2024-05-01T03:12:04.042638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=False)"
   ],
   "id": "d422840c973a0009",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benminh1201/miniconda3/envs/massey/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/benminh1201/miniconda3/envs/massey/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/benminh1201/miniconda3/envs/massey/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 53.86%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0       1  accuracy    macro avg  weighted avg\n",
      "precision     0.538560     0.0   0.53856     0.269280      0.290047\n",
      "recall        1.000000     0.0   0.53856     0.500000      0.538560\n",
      "f1-score      0.700084     0.0   0.53856     0.350042      0.377037\n",
      "support    1257.000000  1077.0   0.53856  2334.000000   2334.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1257    0]\n",
      " [1077    0]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 51.55%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0      1  accuracy    macro avg  weighted avg\n",
      "precision    0.515485    0.0  0.515485     0.257742      0.265724\n",
      "recall       1.000000    0.0  0.515485     0.500000      0.515485\n",
      "f1-score     0.680290    0.0  0.515485     0.340145      0.350679\n",
      "support    516.000000  485.0  0.515485  1001.000000   1001.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[516   0]\n",
      " [485   0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benminh1201/miniconda3/envs/massey/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/benminh1201/miniconda3/envs/massey/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/benminh1201/miniconda3/envs/massey/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:13:29.788567Z",
     "start_time": "2024-05-01T03:13:29.361644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(0.95)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "2dbc168eb55d241e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:13:36.008348Z",
     "start_time": "2024-05-01T03:13:35.996134Z"
    }
   },
   "cell_type": "code",
   "source": "pca.n_components_",
   "id": "d99aef3b75a3e947",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-01T03:14:27.262010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 0.5, 1, 10, 100],\n",
    "              'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf', 'poly', 'linear']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=1, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "best_params = grid.best_params_\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "svm_clf = SVC(**best_params)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ],
   "id": "f0df4869d84f582",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 126 candidates, totalling 630 fits\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e7148b0227c6b9c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
